{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "import sys\n",
    "import liwc\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import multiprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk import word_tokenize\n",
    "from collections import defaultdict, Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(\"..\")\n",
    "from utils import preprocess\n",
    "from utils.tool_simple import get_keywords, list_to_txt, txt_to_list, list_drop_duplicate, many_list_count_sum, list_clean_blank, json_to_dict, dict_to_json\n",
    "from data.dataset import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_dir_data = \"\"\n",
    "max_length_tweet = 28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_dir_data = path_dir_data\n",
    "dict_negative_all = json_to_dict(\n",
    "    os.path.join(path_dir_data, f\"dict_user_negative.json\")\n",
    ")\n",
    "dict_positive_all = json_to_dict(\n",
    "    os.path.join(path_dir_data, f\"dict_user_positive.json\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data_positive= pd.DataFrame.from_dict(dict_positive_all, orient='index')\n",
    "df_data_positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_positive = df_data_positive.to_dict('index')\n",
    "len(dict_positive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data_positive.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data_negative = pd.DataFrame.from_dict(dict_negative_all, orient='index')\n",
    "df_data_negative.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_negative = df_data_negative.to_dict('index')\n",
    "len(dict_negative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data_negative.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data_positive.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data_negative.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_pos_before = df_data_positive['tweet_before_covid'].apply(eval)\n",
    "label_pos_before = [0]*len(list_pos_before)\n",
    "list_pos_after = df_data_positive['tweet_covid_depression'].apply(eval)\n",
    "label_pos_after = [1]*len(list_pos_after)\n",
    "list_pos_before = list(zip(list_pos_before, label_pos_before))\n",
    "list_pos_after = list(zip(list_pos_after, label_pos_after))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LIWC feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LIWC_parse, category_names = liwc.load_token_parser('../resources/LIWC2015_English.dic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_liwc_count(data_label):\n",
    "    data_user, label_user = data_label\n",
    "    data_user = word_tokenize(\" \".join(data_user))\n",
    "    liwc_count = Counter(category for token in data_user for category in LIWC_parse(token))\n",
    "    dict_liwc_counts = dict(liwc_count)\n",
    "    # length_words = sum(dict_liwc_counts.values())\n",
    "    # for category in dict_liwc_counts.keys():\n",
    "    #     dict_liwc_counts[category] = dict_liwc_counts[category] / length_words\n",
    "    dict_liwc_counts['word_length'] = sum(dict_liwc_counts.values())\n",
    "    dict_liwc_counts['label'] = label_user\n",
    "    return dict_liwc_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_threads = 32\n",
    "pbar_data = tqdm(list_pos_before)\n",
    "pool = multiprocessing.Pool(num_threads)\n",
    "list_dict_pos_before = pool.map(get_liwc_count, pbar_data)\n",
    "pool.close()\n",
    "pool.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_threads = 32\n",
    "pbar_data = tqdm(list_pos_after)\n",
    "pool = multiprocessing.Pool(num_threads)\n",
    "list_dict_pos_after = pool.map(get_liwc_count, pbar_data)\n",
    "pool.close()\n",
    "pool.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(list_dict_pos_before), len(list_dict_pos_after)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_liwc_pos_before = pd.DataFrame(list_dict_pos_before)\n",
    "df_liwc_pos_before = df_liwc_pos_before.fillna(0)\n",
    "df_liwc_pos_after = pd.DataFrame(list_dict_pos_after)\n",
    "df_liwc_pos_after = df_liwc_pos_after.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_liwc_pos  = df_liwc_pos_before.append(df_liwc_pos_after)\n",
    "df_liwc_pos.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_liwc_pos.label.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chi2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label == 0\n",
    "df_liwc_pos_0 = df_liwc_pos[df_liwc_pos['label']==0]\n",
    "sum_word_length_0 = sum(df_liwc_pos_0['word_length'])\n",
    "count_0 = pd.Series(df_liwc_pos_0.drop(columns=['word_length', 'label'], axis=1).apply(sum), name='count_0')\n",
    "p_0 = pd.Series(df_liwc_pos_0.drop(columns=['word_length', 'label'], axis=1).apply(sum)/sum_word_length_0, name='p_0')\n",
    "# label == 1\n",
    "df_liwc_pos_1 = df_liwc_pos[df_liwc_pos['label']==1]\n",
    "sum_word_length_1 = sum(df_liwc_pos_1['word_length'])\n",
    "count_1 = pd.Series(df_liwc_pos_1.drop(columns=['word_length', 'label'], axis=1).apply(sum), name='count_1')\n",
    "p_1 = pd.Series(df_liwc_pos_1.drop(columns=['word_length', 'label'], axis=1).apply(sum)/sum_word_length_1, name='p_1')\n",
    "\n",
    "# merge\n",
    "df_count = pd.DataFrame({count_0.name:count_0, p_0.name:p_0, count_1.name:count_1, p_1.name:p_1})\n",
    "df_count = df_count.sort_values(by='count_1', ascending=False)\n",
    "df_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_word_length_0, sum_word_length_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_category_c_p = df_count.to_dict(orient='index')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Significant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import chi2_contingency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def significant_occurrence(name, occurrence_before, occurrence_after, count_before, count_after,  correction=False):\n",
    "    not_after = count_after-occurrence_after\n",
    "    not_before = count_before-occurrence_before\n",
    "    # build 2*2 table\n",
    "    df_chi2 = pd.DataFrame(columns=['occurrence','Not', 'Sum'], index=['after', 'before'])\n",
    "    df_chi2.loc['after'] = [occurrence_after, not_after, count_after]\n",
    "    df_chi2.loc['before'] = [occurrence_before, not_before, count_before]\n",
    "    # cal\n",
    "    chi2, P, dof, ex = chi2_contingency(df_chi2.drop('Sum',axis=1).values, correction=correction)\n",
    "    OR = (occurrence_after*not_before) / (occurrence_before*not_after)\n",
    "    Mie = 1.96/np.sqrt(chi2)\n",
    "    interval_Mie = [ np.power(OR, 1-Mie), np.power(OR, 1+Mie) ]\n",
    "    interval_Mie = np.around(interval_Mie, 2)\n",
    "    \n",
    "    return df_chi2, chi2, P, OR, interval_Mie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_category_chi2 = pd.DataFrame(columns=['category','OR','P','95%CI','Chi2','Count_0','Count_1'])\n",
    "for category in dict_category_c_p.keys():\n",
    "    occurrence_0, occurrence_1 = dict_category_c_p[category]['count_0'], dict_category_c_p[category]['count_1']\n",
    "    p_0, p_1 = dict_category_c_p[category]['p_0'], dict_category_c_p[category]['p_1']\n",
    "    df_chi2, chi2, P, OR, interval_Mie = significant_occurrence(category, occurrence_before=occurrence_0, occurrence_after=occurrence_1, count_before=sum_word_length_0, count_after=sum_word_length_1)\n",
    "    s_before = f\"{int(occurrence_0)} ({p_0*100:1f}%)\"\n",
    "    s_after = f\"{int(occurrence_1)} ({p_1*100:.1f}%)\"\n",
    "    df_category_chi2.loc[len(df_category_chi2)] = [category, OR, P, interval_Mie, chi2, s_before, s_after]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_category_chi2 = df_category_chi2.sort_values(by='P', ascending=True)\n",
    "df_category_chi2 = df_category_chi2[df_category_chi2['P']<0.0001]\n",
    "df_category_chi2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_count.loc[df_category_chi2['category']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_category_chi2_more = df_category_chi2[df_category_chi2['OR']>1].sort_values(by='OR', ascending=False)\n",
    "df_category_chi2_less = df_category_chi2[df_category_chi2['OR']<1].sort_values(by='OR', ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_category_chi2_more[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_category_chi2_more.to_excel(\"df_category_chi2_more.xlsx\", index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_category_chi2_less[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_category_chi2_less.to_excel(\"df_category_chi2_less.xlsx\", index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objs as go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_category_top = df_category_chi2.category.tolist()[:20]\n",
    "list_category_top"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig = go.Figure(data=[\n",
    "#     # go.Bar(name='General', x=list_SNOMED_top, y=df_SNOMED_body_count_percent[:22].percent),\n",
    "#     go.Bar(name='0', x=list_category_top, y=[ dict_category_c_p[category]['p_0'] for category in list_category_top ]),\n",
    "#     go.Bar(name='1', x=list_category_top, y=[ dict_category_c_p[category]['p_1'] for category in list_category_top ])\n",
    "# ])\n",
    "# # Change the bar mode\n",
    "# fig.update_layout(barmode='group')\n",
    "# fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_1 = 'indianred' \n",
    "color_2 = 'lightsalmon' \n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Bar(\n",
    "    x=list_category_top,\n",
    "    y=[ dict_category_c_p[category]['p_0'] for category in list_category_top ],\n",
    "    name='0',\n",
    "    marker_color=color_1,\n",
    "))\n",
    "fig.add_trace(go.Bar(\n",
    "    x=list_category_top,\n",
    "    y=[ dict_category_c_p[category]['p_1'] for category in list_category_top ],\n",
    "    name='1',\n",
    "    marker_color=color_2,\n",
    "))\n",
    "\n",
    "# Here we modify the tickangle of the xaxis, resulting in rotated labels.\n",
    "fig.update_layout(\n",
    "    # title='Symptoms Prevalence of Different variants',\n",
    "    xaxis_tickfont_size=15,\n",
    "    xaxis_tickangle=-45,\n",
    "    yaxis=dict(\n",
    "        title='Prevalence(%)',\n",
    "        titlefont_size=16,\n",
    "        tickfont_size=14,\n",
    "        ticksuffix='%',\n",
    "    ),\n",
    "    legend=dict(\n",
    "        x=0.95,\n",
    "        y=1.0,\n",
    "        bgcolor='rgba(255, 255, 255, 0)',\n",
    "        bordercolor='rgba(255, 255, 255, 0)',\n",
    "        font_size=15\n",
    "    ),\n",
    "    barmode='group',\n",
    "    bargap=0.1, # gap between bars of adjacent location coordinates.\n",
    "    bargroupgap=0.0, # gap between bars of the same location coordinate.\n",
    "    height=500,\n",
    "    width=1000,\n",
    "    template='simple_white'\n",
    ")\n",
    "# fig.write_image(path_dir_figure3+\"symptoms_different_variant.svg\")\n",
    "# fig.write_image(path_dir_figure3+\"symptoms_different_variant.pdf\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('nlp')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ee9d3b8515634c3a0c24e5a00ed0069112c9f27bcf8e0589cc4d9d2654ef861a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
