{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import time\n",
    "import json\n",
    "import copy\n",
    "import emoji\n",
    "import random\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94bd9012-0764-43c5-9c07-4cfe2b17315e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 分类报告\n",
    "from sklearn.metrics import classification_report\n",
    "# 混淆矩阵\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from mlxtend.plotting import plot_confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "# ROC曲线与AUC\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "from sklearn.metrics import RocCurveDisplay\n",
    "from sklearn.metrics import PrecisionRecallDisplay\n",
    "# PR曲线\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import f1_score, recall_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "# split\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(\"..\")\n",
    "from utils import preprocess\n",
    "from utils.tool_simple import get_keywords, list_to_txt, txt_to_list, list_drop_duplicate, many_list_count_sum, list_clean_blank, json_to_dict, dict_to_json, init_logger\n",
    "from data.dataset import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_case = 'max'\n",
    "max_length_tweet = 'max'\n",
    "max_word = 100000\n",
    "path_dir_data = f\"\"\n",
    "path_dir_record = f\"\"\n",
    "if not os.path.exists(path_dir_record):\n",
    "    os.mkdir(path_dir_record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = init_logger(path_dir_record+'tfidf.log')\n",
    "logger.info(f\"num_case: {num_case}\")\n",
    "logger.info(f\"max_length_tweet: {max_length_tweet}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_negative_all = json_to_dict(\n",
    "    os.path.join(path_dir_data, f\"dict_user_negative.json\")\n",
    ")\n",
    "dict_positive_all = json_to_dict(\n",
    "    os.path.join(path_dir_data, f\"dict_user_positive.json\")\n",
    ")\n",
    "logger.info(f\"Loading negative: {len(dict_negative_all)}\")\n",
    "logger.info(f\"Loading positive: {len(dict_positive_all)}\")\n",
    "\n",
    "num_case = (\n",
    "    int(num_case) if not isinstance(num_case, str) else len(dict_positive_all)\n",
    ")\n",
    "dict_negative = get_dict_part(\n",
    "    dict_negative_all,\n",
    "    num_case * len(dict_negative_all) / len(dict_positive_all),\n",
    "    shuffle=False,\n",
    ")\n",
    "dict_positive = get_dict_part(dict_positive_all, num_case, shuffle=False)\n",
    "\n",
    "num_negative, num_positive, list_data_negative, list_data_positive = process_data_merge(\n",
    "    dict_negative, dict_positive, max_length_tweet=max_length_tweet\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_data = list_data_negative + list_data_positive\n",
    "list_label = [0]*num_negative + [1]*num_positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train, data_test, label_train, label_test = train_test_split(list_data, list_label, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info(\n",
    "    f\"Training Size: {len(data_train)}, {sum(label_train)} positive and {len(label_train)-sum(label_train)} negative\"\n",
    ")\n",
    "logger.info(\n",
    "    f\"Testing Size: {len(data_test)}, {sum(label_test)} positive and {len(label_test)-sum(label_test)} negative\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tf-idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_train_vec = np.load(path_dir_modeling_data + 'tfidf_train_t123.npy', allow_pickle=True)\n",
    "# data_test_vec = np.load(path_dir_modeling_data + 'tfidf_test_t123.npy', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_tf = TfidfVectorizer(max_features=max_word, use_idf=True, smooth_idf=True, stop_words='english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_tf.fit_transform(['hello world'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train_vec = vec_tf.fit_transform(data_train)\n",
    "data_test_vec = vec_tf.transform(data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train_vec.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train_vec[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train_vec[0].indices.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(path_dir_record + 'tfidf_train.npy', data_train_vec, allow_pickle=False) \n",
    "np.save(path_dir_record + 'tfidf_test.npy', data_test_vec, allow_pickle=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_test = np.load(\"\", allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_xgb = XGBClassifier().fit(data_train_vec, label_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_pred_xgb = model_xgb.predict(data_test_vec)\n",
    "prob_pred_xgb = model_xgb.predict_proba(data_test_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info(classification_report(label_test, label_pred_xgb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info(f\" acc : {accuracy_score(label_test, label_pred_xgb):.4f}\")\n",
    "logger.info(f\" rec : {recall_score(label_test, label_pred_xgb):.4f}\")\n",
    "logger.info(f\"  f1 : {f1_score(label_test, label_pred_xgb):.4f}\")\n",
    "logger.info(f\"auprc: {average_precision_score(label_test, prob_pred_xgb[:,1]):.4f}\")\n",
    "logger.info(f\"auroc: {roc_auc_score(label_test, prob_pred_xgb[:,1]):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ConfusionMatrixDisplay.from_predictions(label_test, label_pred_xgb, display_labels = ['Normal','Mental'], cmap=plt.cm.Blues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_word_importance = list(zip(vec_tf.get_feature_names(), model_xgb.feature_importances_))    \n",
    "list_word_importance = sorted(list_word_importance, key=lambda x: x[1], reverse=True)\n",
    "for idx, word in enumerate(list_word_importance):\n",
    "    logger.info(word)\n",
    "    if idx>=100:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('nlp')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ee9d3b8515634c3a0c24e5a00ed0069112c9f27bcf8e0589cc4d9d2654ef861a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
