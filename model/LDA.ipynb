{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "from pickle import load, dump\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from gensim.corpora import Dictionary\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "from gensim.models.phrases import Phrases, Phraser\n",
    "from gensim.models import LdaModel, LdaMulticore, LsiModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(\"..\")\n",
    "from utils import preprocess\n",
    "from utils.tool_simple import get_keywords\n",
    "from data.dataset import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Record loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_file = \"\"\n",
    "with open(path_file, 'r') as f:\n",
    "    data_original = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_user, tweet_user_all, tweet_user_all_username = [], [], []\n",
    "dict_username_tweet = {}\n",
    "for idx, line in enumerate(data_original):\n",
    "    if line.startswith('Username'):\n",
    "        username = line.strip().split('Username:')[-1]\n",
    "        if idx:\n",
    "            dict_username_tweet[username] = tweet_user\n",
    "            tweet_user = []\n",
    "    if line.startswith('20'):\n",
    "        line = line.split(':', 2)[-1][3:]\n",
    "        line = preprocess.process_for_modeling(line)\n",
    "        tweet_user.append(line)\n",
    "        tweet_user_all.append(line)\n",
    "        tweet_user_all_username.append(username)\n",
    "print(f\"{len(dict_username_tweet)} users with {len(tweet_user_all)} depression tweet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = ' '.join(tweet_user_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "username = random.choice(list(dict_username_tweet.keys()))\n",
    "dict_username_tweet[username]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'username':tweet_user_all_username, 'full_text':tweet_user_all})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_depress = get_keywords(\"../resources/keywords_depression_strict_list.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_common = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "STOPWORDS_depress = set(STOPWORDS) | set(list_depress) | set(list_common)\n",
    "# STOPWORDS_depress = set(STOPWORDS) | set(list_common)\n",
    "print(len(STOPWORDS), len(list_depress), len(list_common))\n",
    "print(len(STOPWORDS_depress))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = TweetTokenizer()\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"tokens\"] = df.full_text.apply(lambda x: tokenizer.tokenize(x))\n",
    "print(len(df))\n",
    "df[\"tokens\"] = df.tokens.apply(lambda x: [t.lower() for t in x if len(t) > 2 and t.isalpha() and t not in STOPWORDS_depress])\n",
    "print(len(df))\n",
    "df[\"tokens\"] = df.tokens.apply(lambda x: [lemmatizer.lemmatize(t) for t in x])\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = df.tokens.values.tolist()\n",
    "phrases = Phraser(Phrases(corpus))\n",
    "for i in range(len(corpus)):\n",
    "    bigrams = [token for token in phrases[corpus[i]] if \"_\" in token]\n",
    "    corpus[i].extend(bigrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"tokens\"] = df.tokens.apply(lambda x: [t for t in x if t not in STOPWORDS_depress])\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word Cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = df.tokens.values.tolist()\n",
    "long_string = \",\".join([\",\".join([t for t in c if t not in [\"covid\", \"pandemic\"]]) for c in corpus])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create a WordCloud object\n",
    "wordcloud = WordCloud(scale=4, random_state=0, background_color=\"white\", max_words=5000, contour_width=2, contour_color='steelblue', collocations=False)\n",
    "# , max_font_size=50, min_font_size=5\n",
    "# # Generate a word cloud\n",
    "wordcloud.generate(long_string)\n",
    "plt.switch_backend('agg')\n",
    "plt.switch_backend('Agg')\n",
    "# # Visualize the word cloud\n",
    "image = wordcloud.to_image()\n",
    "image.show()\n",
    "# wordcloud.to_file('LDA/word_cloud_depress.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wordcloud.to_file('LDA/word_cloud_depress.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  # save tokens to files\n",
    "file_name = 'LDA/mental_token.csv'\n",
    "df[[\"username\", \"tokens\"]].to_csv(file_name, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pickle import load, dump\n",
    "from ast import literal_eval\n",
    "from datetime import datetime\n",
    "from gensim.corpora import Dictionary\n",
    "from gensim.models import LdaModel, LdaMulticore, LsiModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Topic modeling\n",
    "df = pd.read_csv(file_name, keep_default_na=False)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert strings of lists to lists\n",
    "df.tokens = df.tokens.apply(eval)\n",
    "corpus = df.tokens.values.tolist()\n",
    "dictionary = Dictionary(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# changing these numbers can increase/decrease the run time if needed, but too exclusive will lead to worse results\n",
    "no_below = 5\n",
    "dictionary.filter_extremes(no_below=no_below, no_above=0.5)\n",
    "corpus = [dictionary.doc2bow(tokens) for tokens in corpus]\n",
    "print('vocab size: {}'.format(len(dictionary)))\n",
    "print('documents in corpus: {}'.format(len(corpus)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(f\"LDA/Models/{no_below}/\", exist_ok=True)\n",
    "savefile = f'LDA/Models/{no_below}/all.PICKLE'\n",
    "print('saving dataset to {}...'.format(savefile))\n",
    "dump({'corpus': corpus, 'dictionary': dictionary}, open(savefile, 'wb+'))\n",
    "loaddict = {'corpus': corpus, 'dictionary': dictionary}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#topic model\n",
    "def topic_modeling(num_topics=5):\n",
    "    np.random.seed(0)\n",
    "    temp = dictionary[0]  # This is only to \"load\" the dictionary.\n",
    "    id2word = dictionary.id2token\n",
    "    iterations = 50\n",
    "    passes = 5\n",
    "\n",
    "    print('topics: {}'.format(num_topics))\n",
    "    print('interations: {}'.format(iterations))\n",
    "    print('passes: {}'.format(passes))\n",
    "    print('vocab size: {}'.format(len(dictionary)))\n",
    "    print('documents in corpus: {}'.format(len(corpus)))\n",
    "\n",
    "    model_directory = f\"LDA/Models/{no_below}/\"\n",
    "    os.makedirs(model_directory, exist_ok=True)\n",
    "    model_name = f\"{model_directory}/all_p{passes}_i{iterations}_t{num_topics}\"\n",
    "    print(\"Model: \", model_name)\n",
    "\n",
    "    ##Create new model with desired parameters\n",
    "    # https://radimrehurek.com/gensim/models/ldamulticore.html\n",
    "    model = LdaModel(\n",
    "        corpus=corpus,  # leave commented out for batch training, uncomment to train on full corpus at once\n",
    "        id2word=id2word,\n",
    "        iterations=iterations,\n",
    "        passes=passes,\n",
    "        num_topics=num_topics,\n",
    "        random_state=0\n",
    "    )\n",
    "\n",
    "    top_topics = model.top_topics(corpus)\n",
    "\n",
    "    # Average topic coherence is the sum of topic coherences of all topics, divided by the number of topics.\n",
    "    avg_topic_coherence = sum([t[1] for t in top_topics]) / num_topics\n",
    "    print('\\nAverage topic coherence: %.4f.' % avg_topic_coherence)\n",
    "    # pprint(top_topics)  # prints list of ((list of top probability,term tuples), topic coherence) tuples\n",
    "\n",
    "    print(datetime.now())\n",
    "    try:\n",
    "        print('saving model...')\n",
    "        model.save(model_name)\n",
    "        print('model saved as {}.'.format(model_name))\n",
    "    except Exception as e:\n",
    "        print('saving error: {}'.format(e))\n",
    "    print(\"----------------\", \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_topics = list(range(10, 201, 5))\n",
    "len(n_topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for num_topics in n_topics:\n",
    "    topic_modeling(num_topics=num_topics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perplexity coherence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import LdaModel, LdaMulticore, LsiModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_topics = list(range(10, 201, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perplexity_list = []\n",
    "coherence_list = []\n",
    "f_out = open(\"LDA/new_topics_record.txt\", 'w')\n",
    "for num_topics in n_topics:\n",
    "    model_name = f'LDA/Models/5/all_p5_i50_t{num_topics}'\n",
    "    f_out.write(f\"Loading model of {num_topics} topic \\n\")\n",
    "    lda_model = LdaModel.load(model_name)\n",
    "    topic_list = lda_model.print_topics(num_topics=10, num_words=20)\n",
    "    for topic in topic_list:\n",
    "        f_out.write(f\"{topic[0]} - {topic[1]}\\n\")\n",
    "    f_out.write('\\n')\n",
    "    perplexity_list.append(lda_model.log_perplexity(corpus))\n",
    "    # Average topic coherence is the sum of topic coherences of all topics, divided by the number of topics.\n",
    "    top_topics = lda_model.top_topics(corpus)\n",
    "    avg_topic_coherence = sum([t[1] for t in top_topics]) / num_topics\n",
    "    coherence_list.append(avg_topic_coherence)\n",
    "    break\n",
    "f_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perplexity_list = []\n",
    "coherence_list = []\n",
    "f_out = open(\"LDA/new_topics_record.txt\", 'w')\n",
    "for num_topics in n_topics:\n",
    "    model_name = f'LDA/Models/5/all_p5_i50_t{num_topics}'\n",
    "    f_out.write(f\"Loading model of {num_topics} topic \\n\")\n",
    "    lda_model = LdaModel.load(model_name)\n",
    "    topic_list = lda_model.print_topics(num_topics=10, num_words=20)\n",
    "    for idx, topic in enumerate(topic_list):\n",
    "        list_word = []\n",
    "        for word in str(topic).split('*\"')[1:]:\n",
    "            list_word.append(word.split('\" +')[0])\n",
    "        str_list_word = \", \".join(list_word)[:-3]\n",
    "        f_out.write(f\"{idx} - {str_list_word}\\n\")\n",
    "    f_out.write('\\n')\n",
    "    perplexity_list.append(lda_model.log_perplexity(corpus))\n",
    "    # Average topic coherence is the sum of topic coherences of all topics, divided by the number of topics.\n",
    "    top_topics = lda_model.top_topics(corpus)\n",
    "    avg_topic_coherence = sum([t[1] for t in top_topics]) / num_topics\n",
    "    coherence_list.append(avg_topic_coherence)\n",
    "    # break\n",
    "f_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perplexity_list = np.asarray(perplexity_list)\n",
    "coherence_list = np.asarray(coherence_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "font_size=16\n",
    "# ticks\n",
    "t = np.asarray(range(len(n_topics)))\n",
    "# main plot\n",
    "fig, ax1 = plt.subplots(figsize=(10, 6))\n",
    "plt.xticks(t, n_topics, rotation=90)\n",
    "ax1.set_xlabel('Topics', fontsize=font_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subplot 1\n",
    "color = 'tab:red'\n",
    "ax1.set_ylabel('Perplexity', color=color, fontsize=font_size)\n",
    "p1 = ax1.plot(t, perplexity_list, marker='o', color=color, label = 'Perplexity')\n",
    "b, m = np.polynomial.polynomial.polyfit(t, perplexity_list, 1)\n",
    "# plt.plot(t, b + m * t, '--', color=color)\n",
    "ax1.tick_params(axis='y', labelcolor=color)\n",
    "# ax1.set_ylim([0, 0.26])\n",
    "for tick in ax1.yaxis.get_major_ticks():\n",
    "    tick.label.set_fontsize(font_size-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate a second axes that shares the same x-axis\n",
    "ax2 = ax1.twinx()\n",
    "# subplot 2\n",
    "color = 'tab:blue'\n",
    "ax2.set_ylabel('Model Coherence', color=color, fontsize=font_size)  # we already handled the x-label with ax1\n",
    "p2 = ax2.plot(t, coherence_list, marker='o', color=color, label = 'Model Coherence')\n",
    "b, m = np.polynomial.polynomial.polyfit(t, coherence_list, 1)\n",
    "# plt.plot(t, b + m * t, '--', color=color)\n",
    "ax2.tick_params(axis='y', labelcolor=color)\n",
    "# ax2.set_ylim([0, 0.131])\n",
    "\n",
    "# Pad margins so that markers don't get clipped by the axes\n",
    "plt.margins(0.1)\n",
    "\n",
    "plt.yticks(fontsize=font_size-1)\n",
    "# fig.tight_layout()  # otherwise the right y-label is slightly clipped\n",
    "lns = p1+p2\n",
    "labs = [l.get_label() for l in lns]\n",
    "\n",
    "# adjust legends location\n",
    "ax1.legend(lns, labs, loc=0)\n",
    "\n",
    "# plt.title(\"\", fontsize=font_size)\n",
    "\n",
    "plt.show()\n",
    "fig.savefig(\"LDA/pc5.pdf\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('nlp': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ee9d3b8515634c3a0c24e5a00ed0069112c9f27bcf8e0589cc4d9d2654ef861a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
